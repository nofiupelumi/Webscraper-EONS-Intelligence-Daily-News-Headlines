# name: daily-scraper-and-report

# on:
#   schedule:
#     - cron: '54 16 * * *'  # Adjust cron as needed
#   workflow_dispatch:

# jobs:
#   scrape-and-email:
#     runs-on: ubuntu-latest
#     steps:
#       - name: Increase Swap Space
#         run: |
#           sudo fallocate -l 4G /swapfile
#           sudo chmod 600 /swapfile
#           sudo mkswap /swapfile
#           sudo swapon /swapfile
#       # Checkout repository
#       - name: Checkout repository
#         uses: actions/checkout@v4

#       # Set up Python
#       - name: Set up Python
#         uses: actions/setup-python@v4
#         with:
#           python-version: 3.9

#       # Install dependencies
#       - name: Install dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install webdriver-manager selenium beautifulsoup4 pandas undetected-chromedriver
           

#       # Update CA certificates to fix SSL verification issues
#       - name: Update CA certificates
#         run: sudo apt-get install --reinstall -y ca-certificates

#       # Install Google Chrome
#       - name: Install Google Chrome
#         run: |
#           wget -q -O google-chrome.deb https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
#           sudo dpkg -i google-chrome.deb || sudo apt-get install -f -y

#       # Install ChromeDriver
#       - name: Install ChromeDriver
#         run: |
#           wget -q -O chromedriver.zip https://chromedriver.storage.googleapis.com/$(curl -sS https://chromedriver.storage.googleapis.com/LATEST_RELEASE)/chromedriver_linux64.zip
#           unzip chromedriver.zip -d /usr/local/bin/
#           chmod +x /usr/local/bin/chromedriver

#       # Verify Google Chrome Version
#       - name: Verify Google Chrome Version
#         run: google-chrome --version

#       # Verify ChromeDriver Version
#       - name: Verify ChromeDriver Version
#         run: chromedriver --version

#       # Test ChromeDriver functionality
#       - name: Test ChromeDriver
#         run: |
#           echo "from selenium import webdriver
#           from selenium.webdriver.chrome.service import Service
#           from selenium.webdriver.chrome.options import Options
#           from webdriver_manager.chrome import ChromeDriverManager
#           options = Options()
#           options.add_argument('--headless')
#           options.add_argument('--no-sandbox')
#           options.add_argument('--disable-dev-shm-usage')
#           options.binary_location = '/usr/bin/google-chrome'
#           driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
#           driver.get('https://www.google.com')
#           print(driver.title)
#           driver.quit()" > test_chrome.py
#           python test_chrome.py

#       # Test website connectivity
#       - name: Test website connectivity
#         run: curl -I https://www.ripplesnigeria.com/

     

#       # Run the scraper and email script
#       - name: Run scraper and email script
#         env:
#           USER_EMAIL: ${{ secrets.USER_EMAIL }}
#           USER_PASSWORD: ${{ secrets.USER_PASSWORD }}
#         run: python scraper.py --debug

# name: daily-scraper-and-report

# on:
#   schedule:
#     - cron: '54 16 * * *'  # Adjust cron as needed
#   workflow_dispatch:

# jobs:
#   scrape-and-email:
#     runs-on: ubuntu-latest
#     steps:
#       - name: Checkout Repository
#         uses: actions/checkout@v4

#       - name: Set up Python
#         uses: actions/setup-python@v4
#         with:
#           python-version: 3.9

#       - name: Install Dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install playwright pandas
      
#       - name: Install Playwright Browsers
#         run: playwright install chromium
#       - name: Test website accessibility
#         run: curl -I https://www.ripplesnigeria.com/


#       - name: Run Scraper Script
#         env:
#           USER_EMAIL: ${{ secrets.USER_EMAIL }}
#           USER_PASSWORD: ${{ secrets.USER_PASSWORD }}
#         run: python scraper.py

#       - name: Upload Debug Artifacts
#         if: failure()
#         uses: actions/upload-artifact@v3
#         with:
#           name: debug-files
#           path: |
#             debug_screenshot.png
#             debug_page_content.html
name: Run Colab via Google Apps Script

on:
  schedule:
    - cron: "54 16 * * *"  
  workflow_dispatch:  # Allows manual execution if needed

jobs:
  run_colab:
    runs-on: ubuntu-latest

    steps:
      - name: Call Google Apps Script to Run Colab
        run: |
          curl -X GET "https://script.google.com/macros/s/AKfycbxlu64NCDD96yhCQN-0tITHx7Smu52LFGvLN-p36tET0886EqUJBe1pnPaL1Apn3LJE/exec"

